import { NextResponse } from "next/server";

export async function POST(req: Request) {
  try {
    const { message } = await req.json();

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return NextResponse.json(
        { error: "ğŸ”‘ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙØªØ§Ø­ OpenAI. Ø£Ø¶ÙÙÙ‡ ÙÙŠ .env.local" },
        { status: 500 }
      );
    }

    if (!message || !message.trim()) {
      return NextResponse.json({ error: "Ø£Ø¯Ø®Ù„ Ø±Ø³Ø§Ù„Ø© ØµØ­ÙŠØ­Ø©." }, { status: 400 });
    }

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content:
              "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø§Ø³Ù…Ù‡ Ø¬Ø§Ø²Ø§Ù† AI â€” Ø°ÙƒØ§Ø¡ Ø³Ø¹ÙˆØ¯ÙŠ Ù…Ø³ØªÙ‚Ù„ØŒ ØªØ±Ø¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ³Ø±Ø¹Ø© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ Ø·Ø¨ÙŠØ¹ÙŠ.",
          },
          { role: "user", content: message },
        ],
        temperature: 0.7,
        max_tokens: 800,
      }),
    });

    if (!response.ok) {
      const errText = await response.text();
      console.error("OpenAI Error:", errText);
      return NextResponse.json(
        { error: "âš ï¸ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ." },
        { status: 500 }
      );
    }

    const data = await response.json();
    const reply =
      data?.choices?.[0]?.message?.content ?? "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø§Ù„Ø¢Ù†.";
    return NextResponse.json({ reply });
  } catch (e) {
    console.error("Server Error:", e);
    return NextResponse.json({ error: "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø³ÙŠØ±ÙØ±." }, { status: 500 });
  }
}
