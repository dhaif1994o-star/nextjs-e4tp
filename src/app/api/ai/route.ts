import { NextResponse } from "next/server";
import { PrismaClient } from "@prisma/client";

const prisma = new PrismaClient();

export async function POST(req: Request) {
  try {
    const { text } = await req.json();

    // ğŸ” Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
    const localAnswer = await prisma.info.findFirst({
      where: {
        question: {
          contains: text,
          mode: "insensitive",
        },
      },
    });

    if (localAnswer) {
      return NextResponse.json({ reply: localAnswer.answer + " âœ… (Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©)" });
    }

    // ğŸ§  Ø¥Ø°Ø§ Ù…Ø§ ÙˆØ¬Ø¯ Ø¬ÙˆØ§Ø¨ Ù…Ø­Ù„ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… OpenAI
    const reply = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: text }],
      }),
    });

    const data = await reply.json();
    const answer =
      data.choices?.[0]?.message?.content ||
      "Ù…Ø§ ÙÙ‡Ù…Øª Ø³Ø¤Ø§Ù„ÙƒØŒ Ø­Ø§ÙˆÙ„ ØªØµÙŠØºÙ‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø«Ø§Ù†ÙŠØ© ğŸ¤”";

    return NextResponse.json({ reply: answer });
  } catch (error) {
    console.error("AI Route Error:", error);
    return NextResponse.json(
      { reply: "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ ğŸ˜•" },
      { status: 500 }
    );
  }
}
